{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "#LOAD MODEL\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False)\n",
    "anchor_generator = AnchorGenerator(sizes=((16,), (32,), (64,), (128,), (256,)), aspect_ratios=((0.5, 1.0, 2.0),) * 5)\n",
    "model.rpn.anchor_generator = anchor_generator\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 5)\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, 5)\n",
    "model.rpn.post_nms_top_n_train = 2000\n",
    "model.rpn.post_nms_top_n_test = 2000\n",
    "model.roi_heads.detections_per_img = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD EXISITING SAVED MODEL\n",
    "model_path = 'MODELPATH'  #update path\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "saved_state_dict = torch.load(model_path)\n",
    "model.load_state_dict(saved_state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T11:20:41.786080Z",
     "iopub.status.busy": "2024-03-13T11:20:41.784854Z",
     "iopub.status.idle": "2024-03-13T11:20:42.361194Z",
     "shell.execute_reply": "2024-03-13T11:20:42.360476Z",
     "shell.execute_reply.started": "2024-03-13T11:20:41.786046Z"
    },
    "id": "vdw9-JdeHGFL"
   },
   "outputs": [],
   "source": [
    "#LOAD DATASET\n",
    "\n",
    "class CustDat(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_names, images_directory, masks_directory):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "\n",
    "        :param image_names: A list of image file names (e.g., ['0.png', '1.png', ...])\n",
    "        :param images_directory: The directory where image files are located\n",
    "        :param masks_directory: The directory where mask files are located\n",
    "        \"\"\"\n",
    "        self.image_names = [name for name in image_names if os.path.isfile(os.path.join(images_directory, name)) and not name.startswith('.')]\n",
    "        self.images_directory = images_directory\n",
    "        self.masks_directory = masks_directory\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.images_directory, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Extract the base index of the image to match with masks\n",
    "        base_idx = img_name.split('.')[0]\n",
    "\n",
    "        # Loading separate mask images according to the naming convention\n",
    "        mask_files = [file for file in os.listdir(self.masks_directory) if file.startswith(f\"{base_idx}_\") and file.endswith('.png')]\n",
    "        masks = []\n",
    "        labels = []\n",
    "        for mask_file in mask_files:\n",
    "            mask_path = os.path.join(self.masks_directory, mask_file)\n",
    "            mask = np.array(Image.open(mask_path))\n",
    "            masks.append(mask > 0)\n",
    "\n",
    "\n",
    "            last_char = mask_file[-5]\n",
    "            if last_char == 'g':\n",
    "                labels.append(2)\n",
    "            elif last_char == 'o':\n",
    "                labels.append(3)\n",
    "            elif last_char == 'l':\n",
    "                labels.append(4)\n",
    "            else:\n",
    "                labels.append(1)\n",
    " \n",
    "\n",
    "        num_objs = len(masks)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = torch.stack([torch.tensor(mask, dtype=torch.uint8) for mask in masks])\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "\n",
    "        return T.ToTensor()(img), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "\n",
    "images = sorted(os.listdir(\"genimages/\"))\n",
    "transform = T.ToTensor()\n",
    "def custom_collate(data):\n",
    "  return data\n",
    "\n",
    "num = int(0.8 * len(images))\n",
    "num = num if num % 2 == 0 else num + 1\n",
    "train_imgs_inds = np.random.choice(range(len(images)) , num , replace = False)\n",
    "val_imgs_inds = np.setdiff1d(range(len(images)) , train_imgs_inds)\n",
    "train_imgs = np.array(images)[train_imgs_inds]\n",
    "val_imgs = np.array(images)[val_imgs_inds]\n",
    "\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(CustDat(train_imgs ,'genimages/','masks/') ,\n",
    "                                 batch_size = 1,\n",
    "                                 shuffle = True ,\n",
    "                                 collate_fn = custom_collate ,\n",
    "                                 num_workers = 8,\n",
    "                                 pin_memory = True)\n",
    "\n",
    "val_dl = torch.utils.data.DataLoader(CustDat(val_imgs ,'genimages/','masks/') ,\n",
    "                                 batch_size = 1,\n",
    "                                 shuffle = True ,\n",
    "                                 collate_fn = custom_collate ,\n",
    "                                 num_workers = 8,\n",
    "                                 pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T11:20:59.058539Z",
     "iopub.status.busy": "2024-03-13T11:20:59.057648Z"
    }
   },
   "outputs": [],
   "source": [
    "#TRAINING\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.8, weight_decay=0.0005)\n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "#TRAINING\n",
    "for epoch in range(0,NUM_EPOCHS):\n",
    "    train_epoch_loss = 0\n",
    "    val_epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    #TRAIN LOSS\n",
    "    for i , dt in enumerate(train_dl):\n",
    "        imgs = [dt[i][0].to(device) for i in range(len(dt))]\n",
    "        targ = [dt[i][1] for i in range(len(dt))]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targ]\n",
    "        loss = model(imgs , targets)\n",
    "        losses = sum([l for l in loss.values()])\n",
    "        train_epoch_loss += losses.cpu().detach().numpy()\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    all_train_losses.append(train_epoch_loss)\n",
    "\n",
    "    #TEST LOSS\n",
    "    with torch.no_grad():\n",
    "        for j , dt in enumerate(val_dl):\n",
    "            imgs = [dt[i][0].to(device) for i in range(len(dt))]\n",
    "            targ = [dt[i][1] for i in range(len(dt))]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targ]\n",
    "            loss = model(imgs , targets)\n",
    "            losses = sum([l for l in loss.values()])\n",
    "            val_epoch_loss += losses.cpu().detach().numpy()\n",
    "        all_val_losses.append(val_epoch_loss)\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    print(epoch , \"  \" , train_epoch_loss , \"  \" , val_epoch_loss)\n",
    "\n",
    "torch.save(model.state_dict(), 'MODELPATH')  #update path\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
